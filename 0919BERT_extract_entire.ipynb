{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = \"D:\\\\OneDrive - University of South Carolina\\\\Research\\\\CHQ_Twitter\\\\dataset\\\\0707_all_data\\\\SC_tweets.xlsx\"\n",
    "data = pd.read_excel(file_path, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"D:\\\\OneDrive - University of South Carolina\\\\Research\\\\CHQ_Twitter\\\\dataset\\\\0707_all_data\\\\SC_tweets.feather\"\n",
    "data.to_feather(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>username</th>\n",
       "      <th>postdate</th>\n",
       "      <th>message</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>810979387847819264</td>\n",
       "      <td>555790283</td>\n",
       "      <td>BrownRtbrown</td>\n",
       "      <td>2016-12-19 22:45:27</td>\n",
       "      <td>@DanaPerino @PressSec @TheFive national treasu...</td>\n",
       "      <td>-80.926628</td>\n",
       "      <td>33.631138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>810979516986392576</td>\n",
       "      <td>335937722</td>\n",
       "      <td>GinaaCocky_AF</td>\n",
       "      <td>2016-12-19 22:45:58</td>\n",
       "      <td>we'll jump that nigga</td>\n",
       "      <td>-81.632790</td>\n",
       "      <td>34.724121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>810979872885665792</td>\n",
       "      <td>2763980290</td>\n",
       "      <td>longlivehotd</td>\n",
       "      <td>2016-12-19 22:47:23</td>\n",
       "      <td>Nigga just want to feel real love</td>\n",
       "      <td>-80.926628</td>\n",
       "      <td>33.631138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>810980766268227584</td>\n",
       "      <td>120659589</td>\n",
       "      <td>LabelMeTwiix</td>\n",
       "      <td>2016-12-19 22:50:56</td>\n",
       "      <td>She made a nigga buss two times off the head m...</td>\n",
       "      <td>-79.780312</td>\n",
       "      <td>34.182663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>765917393021440000</td>\n",
       "      <td>534912338</td>\n",
       "      <td>Nierrraaa</td>\n",
       "      <td>2016-08-17 14:25:11</td>\n",
       "      <td>yall niggas made us this way  https://t.co/ZcO...</td>\n",
       "      <td>-80.926628</td>\n",
       "      <td>33.631138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>765917458020589568</td>\n",
       "      <td>3384671872</td>\n",
       "      <td>MissTurnerFMS</td>\n",
       "      <td>2016-08-17 14:25:26</td>\n",
       "      <td>Who can build the longest chain out of one pie...</td>\n",
       "      <td>-80.926628</td>\n",
       "      <td>33.631138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid      userid       username            postdate  \\\n",
       "0  810979387847819264   555790283   BrownRtbrown 2016-12-19 22:45:27   \n",
       "1  810979516986392576   335937722  GinaaCocky_AF 2016-12-19 22:45:58   \n",
       "2  810979872885665792  2763980290   longlivehotd 2016-12-19 22:47:23   \n",
       "3  810980766268227584   120659589   LabelMeTwiix 2016-12-19 22:50:56   \n",
       "4  765917393021440000   534912338      Nierrraaa 2016-08-17 14:25:11   \n",
       "5  765917458020589568  3384671872  MissTurnerFMS 2016-08-17 14:25:26   \n",
       "\n",
       "                                             message  longitude   latitude  \n",
       "0  @DanaPerino @PressSec @TheFive national treasu... -80.926628  33.631138  \n",
       "1                              we'll jump that nigga -81.632790  34.724121  \n",
       "2                  Nigga just want to feel real love -80.926628  33.631138  \n",
       "3  She made a nigga buss two times off the head m... -79.780312  34.182663  \n",
       "4  yall niggas made us this way  https://t.co/ZcO... -80.926628  33.631138  \n",
       "5  Who can build the longest chain out of one pie... -80.926628  33.631138  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0:6, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               # u\"\\U0001F600-\\U0001F64F\"  # emojicons\n",
    "                               # u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               # u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               # u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               # u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               # u\"\\U00002702-\\U000027B0\"\n",
    "                               # u\"\\U00002702-\\U000027B0\"\n",
    "                               # u\"\\U000024C2-\\U0001F251\"\n",
    "                               # u\"\\U0001f926-\\U0001f937\"\n",
    "                               # u\"\\U00010000-\\U0010ffff\"\n",
    "                               # u\"\\u2640-\\u2642\"\n",
    "                               # u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def clean_twts(tw):\n",
    "  # remove urls\n",
    "  pattern = 'https{0,1}:\\/\\/t.co\\/[a-zA-Z0-9]+'\n",
    "  tw = re.sub(pattern, \"\", tw)\n",
    "  # remove @\n",
    "  pattern = '@[a-zA-Z0-9_]+ '\n",
    "  tw = re.sub(pattern, \"\", tw)\n",
    "  tw = remove_emoji(tw)\n",
    "  return tw\n",
    "\n",
    "def clean_twt_row(row):\n",
    "    return clean_twts(row['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "      <th>username</th>\n",
       "      <th>postdate</th>\n",
       "      <th>message</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>message_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>810979387847819264</td>\n",
       "      <td>555790283</td>\n",
       "      <td>BrownRtbrown</td>\n",
       "      <td>2016-12-19 22:45:27</td>\n",
       "      <td>@DanaPerino @PressSec @TheFive national treasu...</td>\n",
       "      <td>-80.926628</td>\n",
       "      <td>33.631138</td>\n",
       "      <td>national treasure is the movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>810979516986392576</td>\n",
       "      <td>335937722</td>\n",
       "      <td>GinaaCocky_AF</td>\n",
       "      <td>2016-12-19 22:45:58</td>\n",
       "      <td>we'll jump that nigga</td>\n",
       "      <td>-81.632790</td>\n",
       "      <td>34.724121</td>\n",
       "      <td>we'll jump that nigga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>810979872885665792</td>\n",
       "      <td>2763980290</td>\n",
       "      <td>longlivehotd</td>\n",
       "      <td>2016-12-19 22:47:23</td>\n",
       "      <td>Nigga just want to feel real love</td>\n",
       "      <td>-80.926628</td>\n",
       "      <td>33.631138</td>\n",
       "      <td>Nigga just want to feel real love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>810980766268227584</td>\n",
       "      <td>120659589</td>\n",
       "      <td>LabelMeTwiix</td>\n",
       "      <td>2016-12-19 22:50:56</td>\n",
       "      <td>She made a nigga buss two times off the head m...</td>\n",
       "      <td>-79.780312</td>\n",
       "      <td>34.182663</td>\n",
       "      <td>She made a nigga buss two times off the head m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>765917393021440000</td>\n",
       "      <td>534912338</td>\n",
       "      <td>Nierrraaa</td>\n",
       "      <td>2016-08-17 14:25:11</td>\n",
       "      <td>yall niggas made us this way  https://t.co/ZcO...</td>\n",
       "      <td>-80.926628</td>\n",
       "      <td>33.631138</td>\n",
       "      <td>yall niggas made us this way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>765917458020589568</td>\n",
       "      <td>3384671872</td>\n",
       "      <td>MissTurnerFMS</td>\n",
       "      <td>2016-08-17 14:25:26</td>\n",
       "      <td>Who can build the longest chain out of one pie...</td>\n",
       "      <td>-80.926628</td>\n",
       "      <td>33.631138</td>\n",
       "      <td>Who can build the longest chain out of one pie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid      userid       username            postdate  \\\n",
       "0  810979387847819264   555790283   BrownRtbrown 2016-12-19 22:45:27   \n",
       "1  810979516986392576   335937722  GinaaCocky_AF 2016-12-19 22:45:58   \n",
       "2  810979872885665792  2763980290   longlivehotd 2016-12-19 22:47:23   \n",
       "3  810980766268227584   120659589   LabelMeTwiix 2016-12-19 22:50:56   \n",
       "4  765917393021440000   534912338      Nierrraaa 2016-08-17 14:25:11   \n",
       "5  765917458020589568  3384671872  MissTurnerFMS 2016-08-17 14:25:26   \n",
       "\n",
       "                                             message  longitude   latitude  \\\n",
       "0  @DanaPerino @PressSec @TheFive national treasu... -80.926628  33.631138   \n",
       "1                              we'll jump that nigga -81.632790  34.724121   \n",
       "2                  Nigga just want to feel real love -80.926628  33.631138   \n",
       "3  She made a nigga buss two times off the head m... -79.780312  34.182663   \n",
       "4  yall niggas made us this way  https://t.co/ZcO... -80.926628  33.631138   \n",
       "5  Who can build the longest chain out of one pie... -80.926628  33.631138   \n",
       "\n",
       "                                     message_cleaned  \n",
       "0                     national treasure is the movie  \n",
       "1                              we'll jump that nigga  \n",
       "2                  Nigga just want to feel real love  \n",
       "3  She made a nigga buss two times off the head m...  \n",
       "4                     yall niggas made us this way    \n",
       "5  Who can build the longest chain out of one pie...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data cleaning\n",
    "data['message_cleaned'] = data.apply(clean_twt_row, axis=1)\n",
    "data.iloc[0:6, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT setup\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(text):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    return input_ids\n",
    "\n",
    "def generate_features(text):\n",
    "    input_ids = tokenize_and_encode(text)\n",
    "    input_ids = input_ids.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    # The last_hidden_state contains the contextualized word embeddings\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    # To obtain a single feature vector for the input text, you can take the mean of the last_hidden_state\n",
    "    features = last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 5000\n",
    "all_features_df = pd.DataFrame()\n",
    "temp_features = []\n",
    "\n",
    "# Splitting the data into chunks of 10,000 rows\n",
    "num_chunks = len(data) // chunk_size + (1 if len(data) % chunk_size else 0)\n",
    "\n",
    "print(num_chunks)\n",
    "\n",
    "for chunk_idx in range(num_chunks):\n",
    "\n",
    "    start_idx = chunk_idx * chunk_size\n",
    "    end_idx = start_idx + chunk_size\n",
    "    \n",
    "    chunk_data = data.iloc[start_idx:end_idx]\n",
    "    \n",
    "    features = pd.DataFrame(chunk_data['message_cleaned'].apply(generate_features).tolist())\n",
    "    features.columns = ['BERT' + str(i + 1) for i in range(features.shape[1])]\n",
    "\n",
    "    # Appending the features DataFrame of the current chunk to the all_features list\n",
    "    temp_features.append(features)\n",
    "\n",
    "    if chunk_idx % 5 == 0:\n",
    "        print(chunk_idx)\n",
    "        temp_features_df = pd.concat(temp_features, axis=0, ignore_index=True)\n",
    "        all_features_df = pd.concat([all_features_df, temp_features_df], axis=0, ignore_index=True)\n",
    "        # all_features_df.to_excel(output_file_path, engine='openpyxl', index=False)\n",
    "        temp_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_features_df = pd.concat(temp_features, axis=0, ignore_index=True)\n",
    "all_features_df = pd.concat([all_features_df, temp_features_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362627, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating all the feature DataFrames to get a single DataFrame\n",
    "# all_features_df = pd.concat(all_features, axis=0, ignore_index=True)\n",
    "all_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BERT1</th>\n",
       "      <th>BERT2</th>\n",
       "      <th>BERT3</th>\n",
       "      <th>BERT4</th>\n",
       "      <th>BERT5</th>\n",
       "      <th>BERT6</th>\n",
       "      <th>BERT7</th>\n",
       "      <th>BERT8</th>\n",
       "      <th>BERT9</th>\n",
       "      <th>BERT10</th>\n",
       "      <th>...</th>\n",
       "      <th>BERT759</th>\n",
       "      <th>BERT760</th>\n",
       "      <th>BERT761</th>\n",
       "      <th>BERT762</th>\n",
       "      <th>BERT763</th>\n",
       "      <th>BERT764</th>\n",
       "      <th>BERT765</th>\n",
       "      <th>BERT766</th>\n",
       "      <th>BERT767</th>\n",
       "      <th>BERT768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266411</td>\n",
       "      <td>-0.271815</td>\n",
       "      <td>-0.046840</td>\n",
       "      <td>0.106725</td>\n",
       "      <td>0.267258</td>\n",
       "      <td>-0.424704</td>\n",
       "      <td>0.172865</td>\n",
       "      <td>0.072938</td>\n",
       "      <td>-0.143964</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>-0.144947</td>\n",
       "      <td>0.224371</td>\n",
       "      <td>-0.254050</td>\n",
       "      <td>-0.213241</td>\n",
       "      <td>0.142444</td>\n",
       "      <td>0.346553</td>\n",
       "      <td>0.161358</td>\n",
       "      <td>0.220109</td>\n",
       "      <td>0.044384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.738933</td>\n",
       "      <td>0.419877</td>\n",
       "      <td>0.307914</td>\n",
       "      <td>0.110020</td>\n",
       "      <td>0.093325</td>\n",
       "      <td>-0.196112</td>\n",
       "      <td>0.423407</td>\n",
       "      <td>0.683323</td>\n",
       "      <td>-0.084137</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198600</td>\n",
       "      <td>-0.241656</td>\n",
       "      <td>-0.201124</td>\n",
       "      <td>-0.098977</td>\n",
       "      <td>-0.060928</td>\n",
       "      <td>-0.241914</td>\n",
       "      <td>-0.060914</td>\n",
       "      <td>-0.450824</td>\n",
       "      <td>0.116016</td>\n",
       "      <td>-0.325667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.415491</td>\n",
       "      <td>-0.067514</td>\n",
       "      <td>0.820043</td>\n",
       "      <td>0.097507</td>\n",
       "      <td>0.250365</td>\n",
       "      <td>-0.330574</td>\n",
       "      <td>0.843664</td>\n",
       "      <td>0.475462</td>\n",
       "      <td>-0.203370</td>\n",
       "      <td>-0.085514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234666</td>\n",
       "      <td>0.127815</td>\n",
       "      <td>0.316786</td>\n",
       "      <td>0.028316</td>\n",
       "      <td>-0.125629</td>\n",
       "      <td>0.204311</td>\n",
       "      <td>0.136583</td>\n",
       "      <td>-0.624107</td>\n",
       "      <td>-0.121403</td>\n",
       "      <td>-0.345228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.181235</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.360862</td>\n",
       "      <td>-0.154296</td>\n",
       "      <td>-0.192688</td>\n",
       "      <td>-0.140606</td>\n",
       "      <td>0.443567</td>\n",
       "      <td>0.865717</td>\n",
       "      <td>-0.200479</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240909</td>\n",
       "      <td>-0.129673</td>\n",
       "      <td>-0.065461</td>\n",
       "      <td>-0.064908</td>\n",
       "      <td>-0.304751</td>\n",
       "      <td>-0.271324</td>\n",
       "      <td>-0.198703</td>\n",
       "      <td>-0.506731</td>\n",
       "      <td>0.113161</td>\n",
       "      <td>-0.013145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.458116</td>\n",
       "      <td>0.344774</td>\n",
       "      <td>0.167026</td>\n",
       "      <td>-0.168113</td>\n",
       "      <td>0.223548</td>\n",
       "      <td>-0.053159</td>\n",
       "      <td>0.655439</td>\n",
       "      <td>0.543069</td>\n",
       "      <td>-0.156358</td>\n",
       "      <td>-0.237110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114369</td>\n",
       "      <td>-0.381655</td>\n",
       "      <td>-0.336731</td>\n",
       "      <td>-0.141827</td>\n",
       "      <td>-0.209108</td>\n",
       "      <td>-0.137198</td>\n",
       "      <td>0.023977</td>\n",
       "      <td>-0.359532</td>\n",
       "      <td>-0.070259</td>\n",
       "      <td>-0.100047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BERT1     BERT2     BERT3     BERT4     BERT5     BERT6     BERT7  \\\n",
       "0  0.266411 -0.271815 -0.046840  0.106725  0.267258 -0.424704  0.172865   \n",
       "1  0.738933  0.419877  0.307914  0.110020  0.093325 -0.196112  0.423407   \n",
       "2  0.415491 -0.067514  0.820043  0.097507  0.250365 -0.330574  0.843664   \n",
       "3  0.181235  0.002691  0.360862 -0.154296 -0.192688 -0.140606  0.443567   \n",
       "4  0.458116  0.344774  0.167026 -0.168113  0.223548 -0.053159  0.655439   \n",
       "\n",
       "      BERT8     BERT9    BERT10  ...   BERT759   BERT760   BERT761   BERT762  \\\n",
       "0  0.072938 -0.143964 -0.004774  ...  0.122944 -0.144947  0.224371 -0.254050   \n",
       "1  0.683323 -0.084137  0.004366  ... -0.198600 -0.241656 -0.201124 -0.098977   \n",
       "2  0.475462 -0.203370 -0.085514  ...  0.234666  0.127815  0.316786  0.028316   \n",
       "3  0.865717 -0.200479 -0.001431  ... -0.240909 -0.129673 -0.065461 -0.064908   \n",
       "4  0.543069 -0.156358 -0.237110  ... -0.114369 -0.381655 -0.336731 -0.141827   \n",
       "\n",
       "    BERT763   BERT764   BERT765   BERT766   BERT767   BERT768  \n",
       "0 -0.213241  0.142444  0.346553  0.161358  0.220109  0.044384  \n",
       "1 -0.060928 -0.241914 -0.060914 -0.450824  0.116016 -0.325667  \n",
       "2 -0.125629  0.204311  0.136583 -0.624107 -0.121403 -0.345228  \n",
       "3 -0.304751 -0.271324 -0.198703 -0.506731  0.113161 -0.013145  \n",
       "4 -0.209108 -0.137198  0.023977 -0.359532 -0.070259 -0.100047  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_df.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to .csv file\n",
    "output_file_path = \"D:\\\\OneDrive - University of South Carolina\\\\Research\\\\CHQ_Twitter\\\\dataset\\\\0707_all_data\\\\BERT_features_SC_tweets.csv\"\n",
    "all_features_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"D:\\\\OneDrive - University of South Carolina\\\\Research\\\\CHQ_Twitter\\\\dataset\\\\0707_all_data\\\\BERT_features_SC_tweets.feather\"\n",
    "all_features_df.to_feather(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"D:\\\\OneDrive - University of South Carolina\\\\Research\\\\CHQ_Twitter\\\\dataset\\\\0707_all_data\\\\BERT_features_SC_tweets.feather\"\n",
    "df_from_feather = pd.read_feather(input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
